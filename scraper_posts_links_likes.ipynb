{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa14bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import pyperclip\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "PROFILE_PATH = \"G:/LinkedIn_Web_Scraper/chrome-profile\"\n",
    "CHROMEDRIVER_PATH = \"G:/LinkedIn_Web_Scraper/chromedriver-win64/chromedriver.exe\"\n",
    "CSV_INPUT = \"profiles.csv\"\n",
    "CSV_OUTPUT = \"linkedin_posts.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1030b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(f\"user-data-dir={PROFILE_PATH}\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "    service = Service(CHROMEDRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "        \"source\": '''\n",
    "            Object.defineProperty(navigator, 'webdriver', {\n",
    "                get: () => undefined\n",
    "            })\n",
    "        '''\n",
    "    })\n",
    "\n",
    "    return driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1db62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_driver()\n",
    "wait = WebDriverWait(driver, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67323b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_delay(min_sec=3, max_sec=6):\n",
    "    time.sleep(random.uniform(min_sec, max_sec))\n",
    "\n",
    "def scroll_down(driver, times=3):\n",
    "    for _ in range(times):\n",
    "        driver.execute_script(\"window.scrollBy({ top: 800, behavior: 'smooth' });\")\n",
    "        human_delay(2, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d132162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_post_links(driver, profile_url):\n",
    "    posts_data = []\n",
    "    driver.get(profile_url)\n",
    "    print(f\"‚û°Ô∏è Visiting profile: {profile_url}\")\n",
    "\n",
    "    # Dynamic scrolling to load all posts\n",
    "    scroll_down(driver)\n",
    "\n",
    "    posts = driver.find_elements(By.CSS_SELECTOR, \"div.feed-shared-update-v2\")\n",
    "    print(f\"üîç Found {len(posts)} posts\")\n",
    "\n",
    "    # Extract username from profile URL for filename\n",
    "    username = re.search(r\"in/([^/]+)/\", profile_url).group(1) if re.search(r\"in/([^/]+)/\", profile_url) else \"unknown_user\"\n",
    "    output_file = f\"{username}.csv\"\n",
    "\n",
    "    if not posts:\n",
    "        with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "            f.write(\"Message\\nThis user has no posts yet.\")\n",
    "        print(f\"‚ÑπÔ∏è This user ({username}) has no posts yet.\")\n",
    "        return posts_data\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"Post URL\", \"Likes\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for i, post in enumerate(posts, 1):\n",
    "            try:\n",
    "                print(f\"‚û°Ô∏è Processing post {i}\")\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({behavior: 'smooth', block: 'center'});\", post)\n",
    "                human_delay(0.5, 1)\n",
    "\n",
    "                # Extract likes\n",
    "                likes = 0\n",
    "                try:\n",
    "                    likes_element = post.find_element(By.CSS_SELECTOR, \"button[data-reaction-details] .social-details-social-counts__reactions-count\")\n",
    "                    likes_text = likes_element.text.strip()\n",
    "                    likes = int(likes_text.replace(',', '')) if likes_text.isdigit() or likes_text.replace(',', '').isdigit() else 0\n",
    "                    print(f\"‚úÖ Extracted likes: {likes}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to extract likes for post {i}: {str(e)}\")\n",
    "\n",
    "                # Extract post URL\n",
    "                post_url = None\n",
    "                try:\n",
    "                    link_elements = post.find_elements(By.CSS_SELECTOR, \"a[href*='linkedin.com/posts'], a[href*='activity-'], [data-urn*='urn:li:activity:'], [data-urn*='activity:'], .update-components-text a\")\n",
    "                    for element in link_elements:\n",
    "                        if element.tag_name == \"a\":\n",
    "                            post_url = element.get_attribute(\"href\")\n",
    "                        else:\n",
    "                            urn = element.get_attribute(\"data-urn\")\n",
    "                            if urn and (\"urn:li:activity:\" in urn or \"activity:\" in urn):\n",
    "                                activity_id = urn.split(\":\")[-1]\n",
    "                                post_url = f\"https://www.linkedin.com/posts/activity-{activity_id}\"\n",
    "                        if post_url:\n",
    "                            print(f\"‚úÖ Extracted post URL directly: {post_url}\")\n",
    "                            break\n",
    "                    if not post_url:\n",
    "                        raise Exception(\"No valid link or urn found\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Failed to extract post URL directly for post {i}: {str(e)}\")\n",
    "                    # Fallback to clipboard method\n",
    "                    try:\n",
    "                        menu_button = post.find_element(By.CSS_SELECTOR, \"div.feed-shared-update-v2__control-menu-container button[aria-expanded]\")\n",
    "                        actions = ActionChains(driver)\n",
    "                        actions.move_to_element(menu_button).pause(0.5).click().perform()\n",
    "                        human_delay(1, 2)\n",
    "                        menu = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.artdeco-dropdown__content-inner\")))\n",
    "                        menu_items = menu.find_elements(By.CSS_SELECTOR, \"li.feed-shared-control-menu__item\")\n",
    "                        for item in menu_items:\n",
    "                            item_text = item.find_element(By.CSS_SELECTOR, \"div.feed-shared-control-menu__dropdown-item\").text.strip().lower()\n",
    "                            if \"copy link to post\" in item_text:\n",
    "                                pyperclip.copy(\"\")\n",
    "                                actions.move_to_element(item.find_element(By.CSS_SELECTOR, \"div.feed-shared-control-menu__dropdown-item\")).click().perform()\n",
    "                                human_delay(2, 3)\n",
    "                                break\n",
    "                        else:\n",
    "                            raise Exception(\"Copy link to post not found\")\n",
    "                        for _ in range(3):\n",
    "                            post_link = pyperclip.paste().strip()\n",
    "                            if \"linkedin.com\" in post_link or post_link.startswith(\"http\"):\n",
    "                                post_url = post_link\n",
    "                                print(f\"‚úÖ Got post link: {post_url}\")\n",
    "                                break\n",
    "                            human_delay(1)\n",
    "                        else:\n",
    "                            raise Exception(\"Failed to get valid post link from clipboard\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Fallback failed for post {i}: {str(e)}\")\n",
    "                        continue\n",
    "\n",
    "                # Save data\n",
    "                writer.writerow({\"Post URL\": post_url, \"Likes\": likes})\n",
    "                posts_data.append({\"url\": post_url, \"likes\": likes})\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing post {i}: {str(e)}\")\n",
    "            finally:\n",
    "                human_delay(0.5, 1)\n",
    "\n",
    "    return posts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc5b7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_profiles():\n",
    "    with open(CSV_INPUT, newline=\"\", encoding=\"utf-8\") as infile, \\\n",
    "         open(CSV_OUTPUT, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"Profile URL\", \"Post URL\"])\n",
    "\n",
    "        for row in reader:\n",
    "            profile_url = row[0].strip()\n",
    "            if not profile_url.startswith(\"http\"):\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n‚û°Ô∏è Visiting profile: {profile_url}\")\n",
    "            try:\n",
    "                driver.get(profile_url)\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "                human_delay(6, 10)\n",
    "\n",
    "                scroll_down(driver, times=random.randint(2, 4))\n",
    "                post_links = extract_post_links(driver)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to scrape profile {profile_url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4815e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚û°Ô∏è Visiting profile: https://www.linkedin.com/in/shanzaywasim/recent-activity/all/\n",
      "üîç Found 7 posts\n",
      "‚û°Ô∏è Processing post 1\n",
      "‚úÖ Extracted likes: 631\n",
      "‚úÖ Menu found for post 1\n",
      "üßæ Found 3 menu items:\n",
      "üßæ Menu item: Save\n",
      "üßæ Menu item: Copy link to post\n",
      "üßæ Menu item: Report post\n",
      "‚úÖ Extracted post URL directly: https://www.linkedin.com/company/university-of-engineering-and-technology-lahore/\n",
      "üìã Attempt 1/5: Raw clipboard content: https://www.linkedin.com/posts/shanzaywasim_%F0%9D%90%80%F0%9D%90%A5%F0%9D%90%A1%F0%9D%90%9A%F0%9D%90%A6%F0%9D%90%9D%F0%9D%90%AE%F0%9D%90%A5%F0%9D%90%A2%F0%9D%90%A5%F0%9D%90%A5%F0%9D%90%9A%F0%9D%90%A1-%F0%9D%90%96%F0%9D%90%9E-%F0%9D%90%9D%F0%9D%90%A2%F0%9D%90%9D-activity-7334593370264121345-_pgE?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFvAQg0BXzGljwy6sM6JsCqdhoXDUT4E_zA\n",
      "‚úÖ Got post link: https://www.linkedin.com/posts/shanzaywasim_%F0%9D%90%80%F0%9D%90%A5%F0%9D%90%A1%F0%9D%90%9A%F0%9D%90%A6%F0%9D%90%9D%F0%9D%90%AE%F0%9D%90%A5%F0%9D%90%A2%F0%9D%90%A5%F0%9D%90%A5%F0%9D%90%9A%F0%9D%90%A1-%F0%9D%90%96%F0%9D%90%9E-%F0%9D%90%9D%F0%9D%90%A2%F0%9D%90%9D-activity-7334593370264121345-_pgE?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFvAQg0BXzGljwy6sM6JsCqdhoXDUT4E_zA\n",
      "‚û°Ô∏è Processing post 2\n",
      "‚úÖ Extracted likes: 26\n",
      "‚úÖ Menu found for post 2\n",
      "üßæ Found 3 menu items:\n",
      "üßæ Menu item: Save\n",
      "üßæ Menu item: Copy link to post\n",
      "üßæ Menu item: Report post\n",
      "‚úÖ Extracted post URL directly: https://www.linkedin.com/search/results/all/?keywords=%23techtipthursday&origin=HASH_TAG_FROM_FEED\n",
      "üìã Attempt 1/5: Raw clipboard content: https://www.linkedin.com/posts/meds-uet_techtipthursday-fpgaprogramming-riscabrv-ugcPost-7285690005417512960-UFdG?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFvAQg0BXzGljwy6sM6JsCqdhoXDUT4E_zA\n",
      "‚úÖ Got post link: https://www.linkedin.com/posts/meds-uet_techtipthursday-fpgaprogramming-riscabrv-ugcPost-7285690005417512960-UFdG?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFvAQg0BXzGljwy6sM6JsCqdhoXDUT4E_zA\n",
      "‚û°Ô∏è Processing post 3\n",
      "‚úÖ Extracted likes: 23\n",
      "‚ö†Ô∏è Menu not found after clicking 3-dot: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0x7ff695a2fe95+79173]\n",
      "\tGetHandleVerifier [0x0x7ff695a2fef0+79264]\n",
      "\t(No symbol) [0x0x7ff6957e9e5a]\n",
      "\t(No symbol) [0x0x7ff695840586]\n",
      "\t(No symbol) [0x0x7ff69584083c]\n",
      "\t(No symbol) [0x0x7ff695894247]\n",
      "\t(No symbol) [0x0x7ff6958689af]\n",
      "\t(No symbol) [0x0x7ff69589100d]\n",
      "\t(No symbol) [0x0x7ff695868743]\n",
      "\t(No symbol) [0x0x7ff6958314c1]\n",
      "\t(No symbol) [0x0x7ff695832253]\n",
      "\tGetHandleVerifier [0x0x7ff695cfa2cd+3004797]\n",
      "\tGetHandleVerifier [0x0x7ff695cf471d+2981325]\n",
      "\tGetHandleVerifier [0x0x7ff695d13370+3107360]\n",
      "\tGetHandleVerifier [0x0x7ff695a4aa1e+188622]\n",
      "\tGetHandleVerifier [0x0x7ff695a522af+219487]\n",
      "\tGetHandleVerifier [0x0x7ff695a38de4+115860]\n",
      "\tGetHandleVerifier [0x0x7ff695a38f99+116297]\n",
      "\tGetHandleVerifier [0x0x7ff695a1f548+11256]\n",
      "\tBaseThreadInitThunk [0x0x7ff91afe7374+20]\n",
      "\tRtlUserThreadStart [0x0x7ff91bd1cc91+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scrape_profiles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.quit()  # Uncomment this to close browser after scraping\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
